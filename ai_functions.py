import asyncio
import os

from dotenv import load_dotenv
from telegram import Update
from telegram.ext import ContextTypes
from together import Together

load_dotenv()

API_URL = "https://api.together.xyz/v1"
TOGETHER_API_KEY = os.getenv("TOGETHER_API_KEY")
AI_MODELS = {
    "DeepSeek": "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
    "Meta Vision": "meta-llama/Llama-Vision-Free",
    "Meta 3.3": "meta-llama/Llama-3.3-70B-Instruct-Turbo-Free",
    "Arcee AFM": "arcee-ai/AFM-4.5B-Preview",
}

SYSTEM_PROMPT = (
"–¢–µ–±–µ –±—É–¥—É—Ç –ø–æ—Å—Ç—É–ø–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã, –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –∑–∞—Ö–æ—á–µ—Ç —á—Ç–æ-—Ç–æ –Ω–∞–ø–∏—Å–∞—Ç—å. –ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∞–≤–∏–ª: \n"
"1. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. \n"
"2. –í—ã–¥–∞–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å–∂–∞—Ç–æ –∏ —á–µ—Ç–∫–æ. \n"
"3. –ù–µ –∑–¥–æ—Ä–æ–≤–∞–π—Å—è, –µ—Å–ª–∏ —Å —Ç–æ–±–æ–π –Ω–µ –ø–æ–∑–¥–æ—Ä–æ–≤–∞–ª–∏—Å—å, –Ω–µ —Å–ø—Ä–∞—à–∏–≤–∞–π, –º–æ–∂–µ—à—å –ª–∏ —á–µ–º-—Ç–æ –µ—â–µ –ø–æ–º–æ—á—å, —Ç–æ–ª—å–∫–æ –æ—Ç–≤–µ—á–∞–π –Ω–∞ "
"–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å. \n"
"4. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–π –¥–∏–∞–ª–æ–≥ —Ç–∞–∫, —á—Ç–æ–±—ã —Ç–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –º–æ–≥–ª–æ –±—ã—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–º –≤ –¥–∏–∞–ª–æ–≥–µ, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤. \n"
"5. –ï—Å–ª–∏ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è –Ω—É–∂–Ω–æ –µ—â–µ —á—Ç–æ-—Ç–æ –∑–Ω–∞—Ç—å, —Ç–æ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—á–∏—Å–ª–∏, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ –¥–ª—è —Ä–µ—à–µ–Ω–∏—è. \n"
"6. –ù–µ –¥–æ–¥—É–º—ã–≤–∞–π –∑–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —á—Ç–æ –æ–Ω –æ—Ç —Ç–µ–±—è —Ö–æ—á–µ—Ç. –ï—Å–ª–∏ –Ω–µ—è—Å–Ω–æ —Å—Ä–∞–∑—É, —Ç–æ —Ç–∞–∫ –∏ –Ω–∞–ø–∏—à–∏, –ø–µ—Ä–µ—á–∏—Å–ª–∏, —á–µ–≥–æ –Ω–µ —Ö–≤–∞—Ç–∏–ª–æ"
". \n"
"7. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞, —Ç–æ –∏—Å–ø–æ–ª—å–∑—É–π –º–µ—Ç–æ–¥ –ø–∞—Ä—Å–∏–Ω–≥–∞ Markdown (–Ω–∞–ø—Ä–∏–º–µ—Ä, –±–ª–æ–∫ –∫–æ–¥–∞ –ø–µ—Ä–µ–¥–∞–≤–∞–π –≤–Ω—É—Ç—Ä–∏ ```)"
)

END_WORDS = ["</think>"]

client = Together(api_key=TOGETHER_API_KEY, base_url=API_URL, max_retries=5)

async def get_ai_response(
    update: Update,
    context: ContextTypes.DEFAULT_TYPE,
    messages: list[dict[str, str]],
    ai_model: str = "deepseek-ai/DeepSeek-R1-Distill-Llama-70B-free",
) -> str:
    stop_animation = asyncio.Event()

    loading_message = await context.bot.send_message(
        chat_id=update.effective_chat.id,
        text="–ü–æ–¥–æ–∂–¥–∏, –¥—É–º–∞—é... "
    )

    async def send_loading_message():
        spinner = ["üïõ", "üïê", "üïë", "üïí", "üïì", "üïî", "üïï", "üïñ", "üïó", "üïò", "üïô", "üïö"]
        while not stop_animation.is_set():
            for frame in spinner:
                if stop_animation.is_set():
                    break
                try:
                    await context.bot.edit_message_text(
                        chat_id=update.effective_chat.id,
                        message_id=loading_message.message_id,
                        text=f"–ü–æ–¥–æ–∂–¥–∏, –¥—É–º–∞—é... {frame}"
                    )
                    await asyncio.sleep(0.15)
                except:
                    break

    loading_task = asyncio.create_task(send_loading_message())

    try:
        loop = asyncio.get_event_loop()
        client_response = await loop.run_in_executor(None, lambda: client.chat.completions.create(
            model=ai_model,
            messages=messages,
        ))

        text_response = client_response.choices[0].message.content

        print(f"AI: {text_response}")

        stop_animation.set()
        await loading_task
        await loading_message.delete()

        return text_response

    except Exception as e:
        context.user_data["ai_response_received"] = True

        print(e)
        await loading_message.edit_text("–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞")

        return ""

    finally:
        # 9. –ì–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞
        stop_animation.set()
        if not loading_task.done():
            loading_task.cancel()

def get_formatted_ai_response(text_response: str) -> str:
    for end_word in END_WORDS:
        if end_word in text_response:
            text_response = text_response.split(end_word)[-1]

    return text_response.replace("<think>", "")

def get_ai_model(model_name: str) -> str:
    return AI_MODELS.get(model_name)
